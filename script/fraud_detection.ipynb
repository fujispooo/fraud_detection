{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCKjQYfn8F2sPVRSjOK9XP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"z3-d0NX7_PQe","executionInfo":{"status":"ok","timestamp":1684718179670,"user_tz":-540,"elapsed":7185,"user":{"displayName":"F R","userId":"06037723555482342541"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import matplotlib.pyplot as plt\n","import numpy as np\n"]},{"cell_type":"code","source":["class ImageClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ImageClassifier, self).__init__()\n","        self.base_model = models.resnet18(pretrained=True)\n","        num_features = self.base_model.fc.in_features\n","        self.fc = nn.Linear(num_features, num_classes)\n","\n","    def forward(self, x):\n","        x = self.base_model(x)\n","        x = self.fc(x)\n","        return x\n"],"metadata":{"id":"Shs2irHGBwS8","executionInfo":{"status":"ok","timestamp":1684718179670,"user_tz":-540,"elapsed":6,"user":{"displayName":"F R","userId":"06037723555482342541"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class GradCAM:\n","    def __init__(self, model, target_layer):\n","        self.model = model\n","        self.target_layer = target_layer\n","        self.activations = None\n","        self.gradients = None\n","\n","    def forward(self, x):\n","        self.activations = []\n","        self.gradients = []\n","\n","        def forward_hook(module, input, output):\n","            self.activations.append(output)\n","\n","        def backward_hook(module, grad_input, grad_output):\n","            self.gradients.append(grad_output[0])\n","\n","        target_layer = self.model._modules[self.target_layer]\n","        hook_a = target_layer.register_forward_hook(forward_hook)\n","        hook_g = target_layer.register_backward_hook(backward_hook)\n","\n","        self.model.eval()\n","        with torch.no_grad():\n","            _ = self.model(x)\n","\n","        hook_a.remove()\n","        hook_g.remove()\n","\n","        self.activations = self.activations[0]\n","        self.gradients = self.gradients[0]\n","\n","    def generate_heatmap(self, target_class):\n","        weights = torch.mean(self.gradients, dim=(2, 3))[0]\n","        heatmap = torch.zeros_like(self.activations[0])\n","\n","        for i, weight in enumerate(weights):\n","            heatmap += weight * self.activations[i]\n","\n","        heatmap = torch.relu(heatmap)\n","        heatmap /= torch.max(heatmap)\n","\n","        return heatmap\n"],"metadata":{"id":"tHN2XYZKByHc","executionInfo":{"status":"ok","timestamp":1684718179671,"user_tz":-540,"elapsed":5,"user":{"displayName":"F R","userId":"06037723555482342541"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYzClyhlLqmX","executionInfo":{"status":"ok","timestamp":1684720786723,"user_tz":-540,"elapsed":26243,"user":{"displayName":"F R","userId":"06037723555482342541"}},"outputId":"77fc7e77-88ab-4aeb-9b82-433d427d483b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from torch.utils.data import ConcatDataset\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","import torch\n","\n","# アノマリーデータのディレクトリのパス\n","anomaly_data_dir = \"/content/drive/MyDrive/path_to_data_directory\"\n","\n","# ノーマルデータのディレクトリのパス\n","normal_data_dir = \"/content/drive/MyDrive/path_to_data_directory\"\n","\n","# 前処理の設定\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# アノマリーデータのデータセットを作成し、ラベルを割り当てる\n","anomaly_dataset = ImageFolder(anomaly_data_dir, transform=transform)\n","anomaly_labels = torch.ones(len(anomaly_dataset))  # アノマリーデータのラベルを1とする\n","\n","# ノーマルデータのデータセットを作成し、ラベルを割り当てる\n","normal_dataset = ImageFolder(normal_data_dir, transform=transform)\n","normal_labels = torch.zeros(len(normal_dataset))  # ノーマルデータのラベルを0とする\n","\n","# データセットとラベルを結合\n","dataset = ConcatDataset([anomaly_dataset, normal_dataset])\n","labels = torch.cat([anomaly_labels, normal_labels])\n","\n","# データローダーの定義\n","batch_size = 32\n","train_dataset = list(zip(dataset, labels))  # データとラベルをタプルとしてまとめる\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"rEmAW6f3CGcr","executionInfo":{"status":"error","timestamp":1684718256327,"user_tz":-540,"elapsed":453,"user":{"displayName":"F R","userId":"06037723555482342541"}},"outputId":"ff39a3f0-5d98-423a-abbe-1b7949812f98"},"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-7a6869b284cc>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# データセットの読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# データローダーの定義\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_data_directory'"]}]},{"cell_type":"code","source":["# データの前処理\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# モデルの初期化\n","num_classes = 2\n","model = ImageClassifier(num_classes)\n","\n","# モデルの学習と評価\n","\n","# データの読み込みと分類ラベルの割り当て\n","# ここでは、datasetsとdataloadersを作成するコードが必要です\n","\n","# オプティマイザと損失関数の定義\n","# オプティマイザと損失関数の定義\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","# モデルの学習と評価\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for images, labels in train_dataloader:\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    train_loss = running_loss / len(train_dataloader)\n","\n","    # バリデーションデータでの評価\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in val_dataloader:\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_accuracy = correct / total\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","# テストデータでの評価\n","model.eval()\n","test_correct = 0\n","test_total = 0\n","\n","with torch.no_grad():\n","    for images, labels in test_dataloader:\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        test_total += labels.size(0)\n","        test_correct += (predicted == labels).sum().item()\n","\n","test_accuracy = test_correct / test_total\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")\n","\n","# テストデータの一部をランダムに表示してヒートマップを生成\n","num_display_images = 5\n","display_images, display_labels = iter(test_dataloader).next()\n","\n","model.eval()\n","gradcam = GradCAM(model, target_layer='layer4')  # Grad-CAMを適用するターゲットレイヤーを指定\n","\n","for i in range(num_display_images):\n","    image = display_images[i].unsqueeze(0)\n","    label = display_labels[i].item()\n","\n","    output = model(image)\n","    _, predicted = torch.max(output.data, 1)\n","    confidence = torch.softmax(output, dim=1)[0, predicted[0]].item()\n","\n","    gradcam.forward(image)\n","    heatmap = gradcam.generate_heatmap(predicted[0])\n","\n","    image = image.squeeze(0)\n","    heatmap = heatmap.numpy()\n","\n","    # 画像とヒートマップを表示\n","    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n","    ax[0].imshow(np.transpose(image, (1, 2, 0)))\n","    ax[0].set_title(f\"Predicted: {predicted.item()}, Confidence: {confidence:.2f}\")\n","    ax[0].axis('off')\n","    ax[1].imshow(heatmap, cmap='jet', alpha=0.5)\n","    ax[1].imshow(np.transpose(image, (1, 2, 0)), alpha=0.5)\n","    ax[1].set_title(\"Grad-CAM Heatmap\")\n","    ax[1].axis('off')\n","\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"Yr1DAX7qB0BW","executionInfo":{"status":"error","timestamp":1684718257474,"user_tz":-540,"elapsed":785,"user":{"displayName":"F R","userId":"06037723555482342541"}},"outputId":"2856fcb5-8c33-4025-bb00-951a53bc040c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 97.8MB/s]\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-7ee6814f9802>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mxmQKE7dCBJo"},"execution_count":null,"outputs":[]}]}